{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b736f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from IPython.display import clear_output, display\n",
    "import os\n",
    "import random\n",
    "import string\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "efef8835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,TensorBoard, CSVLogger, TerminateOnNaN,EarlyStopping\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D,Flatten,Dense\n",
    "from tensorflow.keras.utils import image_dataset_from_directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd4418f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3d573c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5803ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES=[\"Apple Scab\", \"Apple Black Rot\", \"Apple Cedar Apple Rust\", \"Apple Healthy\", \"Corn Maize Cercospora Leaf Spot Gray Leaf Spot\", \"Corn Maize Common Rust\", \"Corn Maize Healthy\", \"Corn Maize Northern Leaf Blight\", \"Grape Black Rot\", \"Grape Esca Black Measles\", \"Grape Healthy\", \"Grape Leaf Blight Isariopsis Leaf Spot\", \"Potato Early Blight\", \"Potato Healthy\", \"Potato Late Blight\", \"Tomato Bacterial Spot\", \"Tomato Early Blight\", \"Tomato Healthy\", \"Tomato Late Blight\", \"Tomato Leaf Mold\", \"Tomato Septoria Leaf Spot\", \"Tomato Spider Mites Two-Spotted Spider Mite\", \"Tomato Target Spot\", \"Tomato Mosaic Virus\", \"Tomato Yellow Leaf Curl Virus\"]\n",
    "INPUT_SIZE=(256,256)\n",
    "BATCH_SIZE=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e24a0bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(image,label):\n",
    "    image = tf.cast(image/255. ,tf.float32)\n",
    "    return image,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a719a316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30647 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = image_dataset_from_directory(\"dataset/train\", batch_size=BATCH_SIZE, labels=\"inferred\", class_names=CLASSES, image_size=INPUT_SIZE,label_mode=\"categorical\").map(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5973f606",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = image_dataset_from_directory(\"dataset/train\", batch_size=BATCH_SIZE, labels=\"inferred\", class_names=CLASSES, image_size=INPUT_SIZE,label_mode=\"categorical\", validation_split=0.2,subset=\"validation\").map(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80c65b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 250 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "test_data = tf.keras.utils.image_dataset_from_directory(\"Dataset/test\", batch_size=BATCH_SIZE, labels=\"inferred\", class_names=CLASSES, image_size=INPUT_SIZE,label_mode=\"categorical\").map(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc2585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"models/model-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
    "callbacks = [ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=False, save_weights_only=False, mode='auto', save_freq='epoch'), \n",
    "             TensorBoard(log_dir='logs', histogram_freq=0, write_graph=True, write_images=False, update_freq='epoch', profile_batch=2, embeddings_freq=0, embeddings_metadata=None), \n",
    "             CSVLogger( \"training_logs/{}.csv\".format(dt.datetime.now().strftime(\"%d/%m/%Y_%H%M%S\")) , separator=',', append=False),\n",
    "             TerminateOnNaN(),\n",
    "             EarlyStopping(monitor='loss', patience=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daff94e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e233adc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(Conv2D(8, (3, 3), padding=\"same\", activation='relu', input_shape=(256, 256, 3)))\n",
    "model.add(Conv2D(16, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding=\"same\", activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(25,activation=\"softmax\"))\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "model.compile(metrics=['accuracy'],loss=\"categorical_crossentropy\",optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aaa044a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_12 (Conv2D)          (None, 256, 256, 8)       224       \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 256, 256, 16)      1168      \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 128, 128, 16)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 128, 128, 32)      4640      \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 128, 128, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 64, 64, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 131072)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 64)                8388672   \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 25)                1625      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,405,577\n",
      "Trainable params: 8,405,577\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3321bd91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10/10 [==============================] - 5s 453ms/step - loss: 3.3605 - accuracy: 0.0632 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 2/15\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 3.0760 - accuracy: 0.1895 - f1_m: 0.0000e+00 - precision_m: 0.0000e+00 - recall_m: 0.0000e+00\n",
      "Epoch 3/15\n",
      "10/10 [==============================] - 5s 463ms/step - loss: 2.6777 - accuracy: 0.3000 - f1_m: 0.1395 - precision_m: 0.2929 - recall_m: 0.0947\n",
      "Epoch 4/15\n",
      "10/10 [==============================] - 5s 470ms/step - loss: 2.6674 - accuracy: 0.2579 - f1_m: 0.0885 - precision_m: 0.3550 - recall_m: 0.0526\n",
      "Epoch 5/15\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 2.7463 - accuracy: 0.2105 - f1_m: 0.1749 - precision_m: 0.5683 - recall_m: 0.1053\n",
      "Epoch 6/15\n",
      "10/10 [==============================] - 5s 479ms/step - loss: 2.5172 - accuracy: 0.2684 - f1_m: 0.2524 - precision_m: 0.8183 - recall_m: 0.1526\n",
      "Epoch 7/15\n",
      "10/10 [==============================] - 5s 474ms/step - loss: 2.4721 - accuracy: 0.3053 - f1_m: 0.2360 - precision_m: 0.7917 - recall_m: 0.1421\n",
      "Epoch 8/15\n",
      "10/10 [==============================] - 5s 480ms/step - loss: 2.3434 - accuracy: 0.3526 - f1_m: 0.3197 - precision_m: 0.8520 - recall_m: 0.2053\n",
      "Epoch 9/15\n",
      "10/10 [==============================] - 5s 475ms/step - loss: 2.5190 - accuracy: 0.2158 - f1_m: 0.1909 - precision_m: 0.8500 - recall_m: 0.1105\n",
      "Epoch 10/15\n",
      "10/10 [==============================] - 5s 484ms/step - loss: 2.3222 - accuracy: 0.3158 - f1_m: 0.2365 - precision_m: 0.8774 - recall_m: 0.1421\n",
      "Epoch 11/15\n",
      "10/10 [==============================] - 5s 482ms/step - loss: 2.2920 - accuracy: 0.3263 - f1_m: 0.2141 - precision_m: 0.8317 - recall_m: 0.1263\n",
      "Epoch 12/15\n",
      "10/10 [==============================] - 5s 476ms/step - loss: 2.0629 - accuracy: 0.4421 - f1_m: 0.3645 - precision_m: 0.8224 - recall_m: 0.2421\n",
      "Epoch 13/15\n",
      "10/10 [==============================] - 5s 480ms/step - loss: 2.0755 - accuracy: 0.4000 - f1_m: 0.3502 - precision_m: 0.7673 - recall_m: 0.2316\n",
      "Epoch 14/15\n",
      "10/10 [==============================] - 5s 471ms/step - loss: 2.2681 - accuracy: 0.3421 - f1_m: 0.2530 - precision_m: 0.7302 - recall_m: 0.1684\n",
      "Epoch 15/15\n",
      "10/10 [==============================] - 5s 483ms/step - loss: 2.1670 - accuracy: 0.3842 - f1_m: 0.3202 - precision_m: 0.8667 - recall_m: 0.2053\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(training_data, steps_per_epoch=20,epochs=500,verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47949694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
